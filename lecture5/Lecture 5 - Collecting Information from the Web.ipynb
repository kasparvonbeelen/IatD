{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Information from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the material are, again, gently stolen from [Doing Computational Social Science with Python](https://github.com/damian0604/bdaca/blob/master/book/bd-aca_book.pdf) written by Damian Trilling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HTTP request methods and status codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Connecting to online documents with `requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests` is an external library that facilitates downloading data from the Web into your Python Notebook. Similar to NLTK `requests` doesn't load automatically but should be imported. This is handled by the `import` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `requests` it becomes fairly easy to read data from the Web into you Notebook, especially \"raw\" text. We need to provide the `.get()` methods with a string that contains a URL (Uniform Resource Locator). The URL below points to Franz Kafka's Metamorphoses on Gutenberg.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "data = requests.get('http://www.gutenberg.org/cache/epub/5200/pg5200.txt')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What operation has the `.get()` method actually performed? Printing the `data` variable does not give us the text, but a short message indicating the **Status Code**.\n",
    "\n",
    "HTTP (or HyperText Transfer Protocal) contains methods to request data. The two most commons ones (supported by all Web browers) are **GET** and **POST**.\n",
    "\n",
    "**[From Wikipedia](https://en.wikipedia.org/wiki/POST_(HTTP))**\n",
    "\n",
    "- The **POST** request method requests that a web server accepts the data enclosed in the body of the request message, most likely for storing it;\n",
    "\n",
    "- The HTTP **GET** request method retrieves information from the server. As part of a GET request, some data can be passed within the URL's query string, specifying (for example) search terms, date ranges, or other information that defines the query.\n",
    "\n",
    "`requests.get()` is the Python tool to execute an HTTP GET request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the `.get()` gives the HTTP status code returned by the GET request method. 200 means that everything is OK. An overview of status codes is given [here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes).\n",
    "\n",
    "One of the most infamous status code is the [**404 Error**](https://en.wikipedia.org/wiki/HTTP_404), which indicates the server could not find the requested information.\n",
    "<img src='https://s3.amazonaws.com/images.seroundtable.com/t-google-404-1303660172.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return to the above example: If we want to print the actual text, we need to access that `.text` attribute of the `data` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of Metamorphosis, by Franz Kafka\r\n",
      "Translated by David Wyllie.\n"
     ]
    }
   ],
   "source": [
    "content = data.text\n",
    "print(content[:90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --Exercise--\n",
    "\n",
    "Can you make a GET request that returns a 404 Error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --Exercise--\n",
    "\n",
    "- Assign the [complete works of William Shakespeare](https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt) to a variable with the name `sh_compl`;\n",
    "- Use the `.get()` method from the requests library;\n",
    "- Perform the operation in only **one line** of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Automatically importing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Dictionaries and JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "- Dictionaries\n",
    "- Counting words, mapping information\n",
    "- Importing JSON data\n",
    "- Nested dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "A dictionary resembles a list, but is more generic data type. In a list, the indices have to be **integers** (i.e. to the position of an item in a sequence); in a dictionary, the indices can be of (almost) **any type**. \n",
    "\n",
    "Before inspecting dictionaries, let's revisit lists for just a moment.\n",
    "\n",
    "Using the index operator, we can retrieve the elements at a certain position (for example my first friend):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example \n",
    "all_my_friends = ['John','Mary','Benny']\n",
    "# retrieve element by index\n",
    "my_first_friend = all_my_friends[0]\n",
    "print(my_first_friend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine having to look up someone's number. Here the index (or key) would be the names of all citizens with a telephone, and the values their numbers. A numerical index does not make sense here because **we want to retrieve the number by name, not by position in the book**. The same applies, of course, to a normal dictionary, where we'd look up translations or descriptions by word. \n",
    "\n",
    "Dictionaries provide you with the data structure that makes such tasks (**looking up values by keys**) exceptionally easy.\n",
    "\n",
    "For example, if we look at the dictionary `telephone_numbers` below, what is Susan's phone number?\n",
    "\n",
    "In Pyhon you can easily look-up a key (the element before the `:`) in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telephone_numbers = {'Frank': 4334030, 'Susan': 400230, 'Guido': 487239}\n",
    "print(telephone_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now print Susan's telephone number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(telephone_numbers['Susan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is Guido's phone number?\n",
    "print(telephone_numbers['Guido'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how similar `telephone_numbers['Susan']` looks to retrieving the *n*-th element in a list, e.g. `my_list[n]`.\n",
    "\n",
    "Of course, you could do something similar with a list (the look-up by key), but that would be very impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telephone_numbers = ['Frank', 4334030, 'Susan', 400230, 'Guido', 487239]\n",
    "print(telephone_numbers[telephone_numbers.index('Susan')+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That's pretty inefficient. The take-home message here is **that lists are not really good if we want two pieces of information together**. Dictionaries come to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you can think of a dictionary as **a mapping** between a set of indices (which are called keys) and a set of values. **Each key maps to a value.** \n",
    "\n",
    "The **association** of a key and a value is called a **key-value** pair or sometimes an **item**.\n",
    "\n",
    "Essentialy, a dictionary **is a mapping between to keys and values**: for example words (key) to their frequencies (value), but we will cover other examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Creating a dictionary\n",
    "\n",
    "* a dictionary is surrounded by **curly brackets** \n",
    "\n",
    "* a dictionary consists of one or more **key:value pairs**, the key is the 'identifier' or \"name\" that is used to describe the value.\n",
    "* the **keys** in a dictionary are **unique**\n",
    "* the syntax for a key/value pair is: `key : value`\n",
    "* and the **key/value** pairs (i.e. **items**) are separated by **commas**.\n",
    "* the keys (e.g. 'Frank') in a dictionary have to be **immutable**\n",
    "* the values (e.g. 8) in a dictionary can by **any python object**\n",
    "* a dictionary can be empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mapping between English and German words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english2deutsch = {'ambulance':'Krankenwagen',\n",
    "                  'clever':'klug',\n",
    "                  'concrete':'Beton'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Please note that **keys** in a dictionary have to be **immutable and uniques**. Lists, therefore, can not appear as keys. \n",
    "* **Anything** can be a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because keys have to be immutable, a list can not appear in this location. This should raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_dict = {['a', 'list']: 8}\n",
    "print(a_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_dict = { 8:['a', 'list']}\n",
    "print(a_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise**: correct the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fout\n",
    "d = ['a'=4:\n",
    "     'a':5,\n",
    "     ['b'] = [1,2,34]\n",
    "    'f':'bb'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correct\n",
    "d = {'a' : 4,\n",
    "     'a_2': 5,\n",
    "     'b' : [1,2,34],\n",
    "    'f':'bb'\n",
    "    }\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: make dictionary which maps three cities to the size of their population. Call it `city2population`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city2population = {'Shanghai' : 24256800,'Beijing' : 21516000, 'Delhi': 16349831}\n",
    "print(city2population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2.1 Adding items to a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one very simple way in order to add a **key:value** pair to a dictionary. Please look at the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english2deutsch = dict()\n",
    "#or try english2deutsch = {}\n",
    "print(english2deutsch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english2deutsch['one'] = 'einz'\n",
    "english2deutsch['two'] = 'zwei'\n",
    "english2deutsch['three'] = 'drei'\n",
    "print(english2deutsch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: add two more cities to `city2population`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city2population['Lagos'] = 16060303\n",
    "city2population['Tianjin'] = 15200000\n",
    "print(city2population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that key:value pairs get overwritten if you assign a different value to an existing key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english2deutsch = dict()\n",
    "print(english2deutsch)\n",
    "english2deutsch['one'] = 'einz?'\n",
    "print(english2deutsch)\n",
    "english2deutsch['one'] = 'zwei?'\n",
    "print(english2deutsch)\n",
    "english2deutsch['one'] = 'drei?'\n",
    "print(english2deutsch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise**: overwrite the value for the last key you added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city2population['Tianjin'] = 15200001\n",
    "print(city2population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Inspecting the dictionary\n",
    "\n",
    "In a dictionary we store values we'd like to inspect later by their keys. **Common situations are**:\n",
    "- mapping words to frequencies (values are integers, floats)\n",
    "- mapping names to a person's individual characteristics (age, gender, etc) (values are strings or numbers)\n",
    "- mapping dates to counts (creating timelines) (values are integers, floats)\n",
    "- mapping bands to their songs titles (values are lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic operation on a dictionary is a **look-up**. Simply enter the key and the dictionary returns the value. In the example below, we mapped movies to their box-office performance. Keys are the Movie Titles, and values represent the ticket sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo = {'Avatar': 27879650875, 'Titanic': 2187463944, 'Star Wars: The Force Awakens': 2068223624}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bo['Avatar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If the key is not in the dictionary, Python will raise a ``KeyError``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo['The Lion King']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membership operators** appear often to check whether a dictionary contains a specific key. Let's assume we posses a dictionary that maps writers to their date of birth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer2dob = {'Edgar Allan Poe': 'January 19, 1809',\n",
    "             'Virginia Woolf':'January 25, 1882',\n",
    "             'James Joyce':'February 2, 1882'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am curious whether I appear in this illustrous set of authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Do I appear in this dictionary?')\n",
    "writer2dob['Kaspar von Beelen']\n",
    "print('Yes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn, obviously I am not, and Python raises a `KeyError`, which would be annoying when running a larger program, because, as you've noticed, **the program did not get to the last `print()` statement** (meaning it crashed). So, let's write a little program that prints \"X is in the dictionary\" if a particular writer appears in the collection and \"X is NOT in the dictionary\" if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tip a membership operation looks as follows:\n",
    "'Edgar Allan Poe' in writer2dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'Kaspar von Beelen' \n",
    "\n",
    "print('Does ' + name +' appear in this dictionary?')\n",
    "print('\\n')\n",
    "\n",
    "if name in writer2dob:\n",
    "    print(writer2dob[name])\n",
    "else:\n",
    "    print(name + ' not in dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Dictionary Methods\n",
    "### .get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid checking all the time for membership or getting a `KeyError` when a key does not appear in the dictionary, you can use the ``get`` method. The **first argument** is the **key** to look up, the **second argument** defines the **value** to be returned if the key is not found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(bo.get('The Lion King','Not in Dictionary'))\n",
    "# a good alternative could be \n",
    "print(bo.get('Avatar',False))\n",
    "print(bo.get('The Lion King',False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Other methods allow us to access the different components of the dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **keys** method returns the keys in a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_grades = {'Frank': 8, 'Susan': 7, 'Guido': 10}\n",
    "the_keys = student_grades.keys()\n",
    "print(the_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **values** method returns the values in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_values = student_grades.values()\n",
    "print(the_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the other built-in functions to inspect the keys and values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_values = student_grades.values()\n",
    "print(len(the_values)) # number of values in a dict\n",
    "print(max(the_values)) # highest value of values in a dict\n",
    "print(min(the_values)) # lowest value of values in a dict\n",
    "print(sum(the_values)) # sum of all values of values in a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **items** method returns a list of **tuples** (we have a look at tuples later), which allows us to easily loop through a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_grades = {'Frank': 8, 'Susan': 7, 'Guido': 10}\n",
    "print(student_grades.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sorted()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to sort the dictionary by either their keys or values. The Python `sorted()` function is very useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_grades = {'Frank': 8, 'Susan': 7, 'Guido': 10}\n",
    "print(student_grades.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(student_grades.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by value, in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(student_grades.items(),key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by value, in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(student_grades.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Sort `word_counts`\n",
    "- Alphabetically\n",
    "- By word frequency in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = {',': 1, '.': 1, 'announced': 1, 'are': 1,  'be': 2, 'bosses': 1, 'by': 1,\n",
    "         'company': 1,'failing': 1,'fines': 1,'government': 1, 'hit': 1, 'huge': 1,'irresponsible': 1,\n",
    "         'line': 1, 'may': 1, 'own': 1,'pension': 1, 'plans': 1, 'protect': 1,'schemes': 1,\n",
    "         'their': 1,'theresa': 1, 'to': 3, 'under': 1, 'weeks': 1, 'while': 1, 'who': 1,\n",
    "         'with': 1, 'within': 1, 'workers': 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sorted(word_counts.items()))\n",
    "print(sorted(word_counts.items(),key = lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Iterating over dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since dictionaries are iterable objects, we can iterate through our good reads collection as well. This will iterate over the *keys* of a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_reads = {\"The Magic Mountain\":9,\n",
    "             \"The Idiot\":7,\n",
    "             \"Don Quixote\": 9.5}\n",
    "\n",
    "for book in good_reads:\n",
    "    print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate over both the keys and the values of a dictionary, this is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_reads.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x, y in good_reads.items():\n",
    "    print(x + \" has score \" + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Notice that we write `for x, y in` and not `for x in`. Because we are interested in titles and scores as seperate items we unpack the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just to compare\n",
    "for x in good_reads.items():\n",
    "    print(x + \" has score \" + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Example Counting with dictionaries\n",
    "\n",
    "Dictionaries are very useful to keep track of our data, for example by counting words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Obama was the president of the USA' # assign the string to the variable sentence\n",
    "words = sentence.split() # split the sentence\n",
    "word2freq = {} # initialize an empty dictionary, here we store the word counts\n",
    "# i.e. word2freq is a mapping from words to their frequencies\n",
    " \n",
    "\n",
    "for word in words: # loop over all the words, word takes each word in turn\n",
    "    if word in word2freq: # add 1 to the dictionary if the keys exists, here we perform membership check on the keys\n",
    "        word2freq[word] += 1 # notice that we use the shorthand for incremental count\n",
    "                             # which as an abbraviations for  word2freq[word] =  word2freq[word] + 1\n",
    "    else: # if the above condition does not hold (word does not appear as key in the dictionary) than set the key's value to one\n",
    "        word2freq[word] = 1 # set default value to 1 if key does not exists \n",
    "\n",
    "    print('Word added = ',word, 'Updated dictionary = ',word2freq)\n",
    "\n",
    "print('\\n')\n",
    "print(word2freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot is happening in the previous code block; the examples below aim to clarify the individual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `if` and `else`: see Notebook 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change x to see how if else works\n",
    "\n",
    "x = 5\n",
    "\n",
    "if x >= 0:\n",
    "    print(x,' is positive or zero.')\n",
    "else:\n",
    "    print(x, ' is negative.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Line 8 (and implicitly line 11): Membership check on the keys of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2fr = {'USA': 1, 'of': 1, 'president': 1, 'the': 2, 'was': 1, 'Obama': 1}\n",
    "\n",
    "\n",
    "print('USA' in w2fr) # in does memership check on the keys if not method is appended to the dictionary\n",
    "print(1 in w2fr) # it does not check if an items appears as values\n",
    "print(1 in w2fr.values()) # unless you caled th values methods of course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Line 9 and line 12: Updating (9) and setting (12) dictionaries a key\n",
    "\n",
    "Why do we distinguish between updating and setting a key? \n",
    "\n",
    "If we'd only update (which makes sense somehow) Python would raise a `KeyError` because the value for the key we want to increment does not appear yet in the dictionary. For this reason we explicitly set a default (start) value for each new key (i.e. each word which does not appear in the dictionary--in which case the membership condition `in` returns `False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2fr = {'USA': 1, 'of': 1, 'president': 1, 'the': 2, 'was': 1, 'Obama': 1}\n",
    "\n",
    "print('Obama has frequency ',w2fr['Obama'])\n",
    "w2fr['Obama']+=1 \n",
    "print('Obama has frequency ',w2fr['Obama'])\n",
    "\n",
    "# remember +=1 is equal to var = var + 1 \n",
    "# but this is not recommended\n",
    "#w2fr['Obama'] = w2fr['Obama'] + 1 \n",
    "#print('Obama has frequency ',w2fr['Obama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to update the value for a word which key is not in the dictionary, Python throws back a `KeyError`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2fr['Barack']+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we have to add the key first, and update it once we encounter it a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2fr['Barack'] = 1 # set key\n",
    "w2fr['Barack'] += 1 # update key, increment count with one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `setdefault()` method\n",
    "\n",
    "The `setdefault()` method simplifies the above code by automatically checking if a key exists, and if not, setting a default value for this key. This method takes two arguments, the key to be set, and the default value for the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Obama was the president of the USA' # assign the string to the variable sentence\n",
    "words = sentence.split() # split the sentence\n",
    "word2freq = {} # initialize an empty dictionary, here we store the word counts\n",
    "# i.e. word2freq is a mapping from words to their frequencies\n",
    " \n",
    "\n",
    "for word in words: # loop over all the words, word takes each word in turn\n",
    "    \n",
    "    word2freq.setdefault(word,0) # if keys not appear\n",
    "    word2freq[word] += 1 # notice that we use the shorthand for incremental count\n",
    "    \n",
    "    print('Word added = ',word, 'Updated dictionary = ',word2freq)\n",
    "\n",
    "print('\\n')\n",
    "print(word2freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easier ways to count words with Python\n",
    "\n",
    "As counting items in a list is such a common task, Python comes with other tools that make it user to obtain frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sentence = 'Obama was the president of the USA he is no longer the president of the USA' # assign the string to the variable sentence\n",
    "words = sentence.split() # split the sentence\n",
    "wf = Counter(words)\n",
    "print(wf) # Counter works very much like a dictionary\n",
    "print(wf['the']) # you can look up a word by key\n",
    "print(wf['aa']) # it returns zero if the word does not appear\n",
    "print(wf.most_common(2)) # you can rank the words by their frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to discover what you can do with a `Counter` object use `help()` or `dir()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pop()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete keys with the `pop` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(wf)\n",
    "wf.pop('the')\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `update()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`update()` merges to dictionaries, i.e. combines the word counts of two different documents in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(Counter.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf1 = Counter('Obama was the president of the USA '.split())\n",
    "wf2 = Counter('he is no longer the president of the USA'.split())\n",
    "print(wf1)\n",
    "print(wf2)\n",
    "wf1.update(wf2)\n",
    "print('')\n",
    "print(wf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: download Volume I and II of Schopenhauer's 'The World as Will and Idea'\n",
    "- As previously, use requests to download the page from Gutenberg\n",
    "- `word_tokenize()` each of the books\n",
    "- Compute the word frequencies using `Counter()`\n",
    "- Get the hundred most common words (`most_common`)\n",
    "- Which of the common words in volume I are not that common in volume II? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "vol_i = 'http://www.gutenberg.org/files/38427/38427-0.txt'\n",
    "vol_ii = 'http://www.gutenberg.org/files/40097/40097-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_vol_i = requests.get(vol_i).text\n",
    "tokens = word_tokenize(text_vol_i)\n",
    "wf = Counter(tokens)\n",
    "wf.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Count song titles by year (making timelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply these techniques to studying our song titles corpus. \n",
    "\n",
    "First we make a little program that collects the counts of a search term by year. This will allow is to make timelines that plot the evolution of a topic by year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize\n",
    "url = 'https://labrosa.ee.columbia.edu/millionsong/sites/default/files/AdditionalFiles/tracks_per_year.txt'\n",
    "data = requests.get(url).text.strip() # download the song titles\n",
    "song_titles = data.strip().split('\\n') # split the string into lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year2counts = {} # create an empty dictionary here we map years to the frequency of a word\n",
    "\n",
    "search = 'love' # define your search term here\n",
    "\n",
    "for row in song_titles: # iterate over the song_titles variable\n",
    "\n",
    "    year,song_id,group,title = row.split('<SEP>') # unpack the row using multiple assignment\n",
    "    # cast year as an integer with int()\n",
    "    year = int(year)\n",
    "    # set the default value for key year to 0\n",
    "    year2counts.setdefault(year,0)\n",
    "    # lowercase the title\n",
    "    title_lower = title.lower()\n",
    "    # tokenize the lowercased title\n",
    "    words = word_tokenize(title_lower)\n",
    "    \n",
    "    if search in words: # membership check, does the word love appear in the list called words\n",
    "        year2counts[year] +=1 # add one if the condition holds\n",
    "\n",
    "# print the results sorted by year\n",
    "print(sorted(year2counts.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily plot the time series using functions from an external library called **Pandas**. The code below is just to help you plotting your data, do not worry about it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "%matplotlib inline\n",
    "series = pandas.Series(year2counts)\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Can we conclude that \"love\" has become a more popular theme in pop culture over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ideally, we'd like to calculate the propability that a song from a certain year is about love. This is relatively straightforward: we have to divide the number of songs about love from year X by the total number of songs from year X.\n",
    "\n",
    "To program below features therefore a small addition: the dictionary `wf` that *also* tracks the number of songs by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year2counts = {} # create an empty dictionary here we map years to the frequency of a word\n",
    "year2counts_all = {}\n",
    "\n",
    "search = 'love' # define your search term here\n",
    "\n",
    "for row in song_titles: # iterate over the song_titles variable\n",
    "\n",
    "    year,song_id,group,title = row.split('<SEP>') # unpack the row using multiple assignment\n",
    "    # cast year as an integer with int()\n",
    "    year = int(year)\n",
    "    # set the default value for key year to 0\n",
    "    year2counts.setdefault(year,0)\n",
    "    # lowercase the title\n",
    "    title_lower = title.lower()\n",
    "    # tokenize the lowercased title\n",
    "    words = word_tokenize(title_lower)\n",
    "    \n",
    "    year2counts_all.setdefault(year,0)\n",
    "    year2counts_all[year]+=1\n",
    "    \n",
    "    if search in words: # membership check, does the word love appear in the list called words\n",
    "        year2counts[year] +=1 # add one if the condition holds\n",
    "\n",
    "# print the results sorted by year\n",
    "print(sorted(year2counts.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a moment to study the total number of songs by year, we also see an increase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the total number of songs by year\n",
    "series = pandas.Series(year2counts_all)\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason, the **relative frequency of a word will tell us more than the absolute frequency**--almost every search term we define will show an increase over time. Below we add a few more lines to divide the number of songs about love **by the total number of songs** for that specific year. This is called **normalization**.\n",
    "\n",
    "Because we defined the two mappings (year to counts) earlier, this becomes a relatively straightforward task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the probability that a song is about love \n",
    "# create an empty dictionary\n",
    "\n",
    "ratios = {}\n",
    "\n",
    "for key, value in year2counts.items():\n",
    "    ratios[key] = year2counts.get(key,0) / year2counts_all[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "pandas.Series(ratios).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Can you plot the chronological evolution of another term (such as \"dirty\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy-paste your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Recap\n",
    "\n",
    "To finish this section, here is an overview of the new concepts and functions you have learnt. Make sure you understand them all.\n",
    "\n",
    "-  dictionary\n",
    "-  indexing or accessing keys of dictionaries\n",
    "-  adding items to a dictionary\n",
    "-  `.keys()`\n",
    "-  `.values()`\n",
    "-  `.get()`\n",
    "-  `pandas.Series().plot()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous section covered the most basic elements of Python dictionaries. You know now how to assign values to variables, keys to values etc. A variable is a **box** that can contain almost anything. Instead of strings and integers, we can also analyse  **a whole corpus of Tweets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we used all tweets of the current American President. These we obtained via the [Trump Twitter Archive](http://www.trumptwitterarchive.com/archive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is a [JSON](https://en.wikipedia.org/wiki/JSON) file in which each item is a tweet. The cell below shows the first tweet of the collection. It may seem difficult to read JSON notation, but there are various tools to help you. Go for example to this [JSON viewer](http://jsonviewer.stack.hu/) and copy paste the text into the cell below.\n",
    "\n",
    "Basically as JSON object combines Python lists and dictionaries. As it is a very common data type, Python has some libraries to process and read JSON data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``{\"source\":\"Twitter for iPhone\",\n",
    "   \"text\":\"The Tax Cut Bill is coming along very well, great support. With just a few changes, some mathematical, the middle class and job producers can get even more in actual dollars and savings and the pass through provision becomes simpler and really works well!\",\n",
    "   \"created_at\":\"Mon Nov 27 14:24:36 +0000 2017\",\n",
    "   \"retweet_count\":15663,\n",
    "   \"favorite_count\":79868,\n",
    "   \"is_retweet\":false,\n",
    "   \"id_str\":\"935152378747195392\"}``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks almost exactly as a dictionary! To **convert** this JSON item to a proper Python object we can use the `json.loads()` method from the `json` library. `loads()` reads a string and transforms it to a Python readable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "tweet = json.loads('''{\"source\":\"Twitter for iPhone\",\n",
    "                    \"text\":\"The Tax Cut Bill is coming along very well, great support. With just a few changes, some mathematical, the middle class and job producers can get even more in actual dollars and savings and the pass through provision becomes simpler and really works well!\",\n",
    "                    \"created_at\":\"Mon Nov 27 14:24:36 +0000 2017\",\n",
    "                    \"retweet_count\":15663,\n",
    "                    \"favorite_count\":79868,\n",
    "                    \"is_retweet\":false,\n",
    "                    \"id_str\":\"935152378747195392\"}''')\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can treat the `tweet` as a dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the number of retweets of the tweet defined above\n",
    "print(tweet['retweet_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load the whole corpus from disk, but we need some additional syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open('data/trump_tweets.json','r'))\n",
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous cell raised a `UnicodeError`, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "data = json.load(codecs.open('data/trump_tweets.json','r',encoding='utf-8'))\n",
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the loaded JSON corpus is actually a `list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in this `list` is a `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Store all retweet counts in a list named `retweet_count`. Ignore the retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retweet_counts = []\n",
    "for tweet in data:\n",
    "    retweet_counts.append(tweet['retweet_count'])\n",
    "print(retweet_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What is the maximum retweet count? What is the minimum?\n",
    "> use max(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max(retweet_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Compute the the average retweet count? Use the `sum` and `len` functions.\n",
    "> average = sum of items in the list / number of items in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average = sum(retweet_counts)/len(retweet_counts)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy library provides tools for computing such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mock_example = [i**2 for i in range(4,100,3)]\n",
    "print(mock_example)\n",
    "print(np.mean(mock_example))\n",
    "print(np.median(mock_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries are useful for **mapping** two series. Let's map the 'id_str' to the actual 'text' of the tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2text = {}\n",
    "for tweet in data:\n",
    "    id2text[tweet['id_str']] = tweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(id2text.items())[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Printing the most popular tweets.\n",
    "- Map 'text' to 'retweet_count' (Assume for a moment that each tweet text is unique);\n",
    "- sort the mappying by value in the descending order `sorted()`;\n",
    "- and print the text of the five most popular tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text2retweet = {}\n",
    "for tweet in data:\n",
    "    text2retweet[tweet['text']] = tweet['retweet_count']\n",
    "\n",
    "sorted(text2retweet.items(),key = lambda x: x[1],reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Lastly, make a frequency dictionary for tweets that are more popular on average with respect to  their retweet count. Save these word counts in `is_popular`, the others in `not_popular`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular, not_popular = [],[]\n",
    "for tweet in data:\n",
    "    if tweet['retweet_count'] > average:\n",
    "        popular.extend(word_tokenize(tweet['text']))\n",
    "    else:\n",
    "        not_popular.extend(word_tokenize(tweet['text']))\n",
    "        \n",
    "print(Counter(popular).most_common(100))\n",
    "print(Counter(not_popular).most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader Sentiment Analyzer\n",
    "[from Github](https://github.com/cjhutto/vaderSentiment): VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\n",
    "\n",
    "VADER uses a lexicon (a mapping of words to sentiment values, e.g bad=-1.0, good=+1.0) to compute the sentiment (positivity or negativity) of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader\n",
    "analyzer = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can test VADER yourself by changing the value of the ``text`` variable, and running the code block. \n",
    "\n",
    "Can you trick the system? Not very easy isn't it?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Not interesting.\"\n",
    "vs = analyzer.polarity_scores(text)['compound']\n",
    "print(\"{:_<65} {}\".format(text, str(vs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Find the most positive and negative tweets in the corpus. Map tweets text to their sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text2sentiment = {}\n",
    "for tweet in data:\n",
    "    text2sentiment[tweet['text']] = analyzer.polarity_scores(tweet['text'])['compound']\n",
    "sorted(text2sentiment.items(),key = lambda x:x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: JSON and the New York Times API\n",
    "Retrieving data from the **New York Times API** (Application Programming Interface)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below you see an example of a JSOM file that represent an article retrieved via the New York Times API. Copy-paste this example http://jsonviewer.stack.hu/ to inspect the document's structure.\n",
    "\n",
    "``\n",
    "{\"status\":\"OK\", \"copyright\":\"Copyright (c) 2017 The New York Times Company. All Rights Reserved.\", \"response\": {\"docs\":[{\"web_url\": \"https://query.nytimes.com/gst/abstract.html?res=9D03E5D71E3AE433A25753C3A9649D946696D6CF\", \"snippet\":\"\\\"But Colonel ROOSEVELT,\\\" I suggested, \\\"is advocating universal service as a permanent thing.\\\"\",\"abstract\":\"for endless militarism, editorial\",\"print_page\":\"E2\",\"blog\":{},\"source\":\"The New York Times\",\"multimedia\":[],\"headline\":{\"main\":\"FOR ENDLESS MILITARISM.\"},\"keywords\":[{\"isMajor\":null,\"rank\":0,\"name\":\"subject\",\"value\":\"EUROPEAN WAR\"},{\"isMajor\":null,\"rank\":0,\"name\":\"subject\",\"value\":\"PEACE AND MEDIATION\"},{\"isMajor\":null,\"rank\":0,\"name\":\"subject\",\"value\":\"OFFICIAL OVERTURES AND STATEMENTS\"}],\"pub_date\":\"1917-12-30T00:00:00Z\", \"document_type\":\"article\",\"type_of_material\":\"Editorial\",\"_id\":\"4fc079c745c1498b0d307c64\",\"word_count\":692,\"score\":0.0}]}}\n",
    "``\n",
    "\n",
    "Please note that the JSON document has a **tree-like shape** (head nodes with branches).\n",
    "\n",
    "Many institutions provide web APIs, allowing users to access information about their collections in JSON via simple HTTP requests. But how to access the historical archive of the New York Times?\n",
    "\n",
    "First, get an API Key on: https://developer.nytimes.com/\n",
    "\n",
    "In the examples below, the api-key is replaced by ``###``. Please put your own key there.\n",
    "\n",
    "After you received the key, you can interact with the API using URLs as queries. The URL below is an example in which I wanted to find all articles mentioning \"Armenia\" during the First World War. \n",
    "\n",
    "https://api.nytimes.com/svc/search/v2/articlesearch.json?q=armenia&begin_date=19140101&end_date=19180101&api-key=###\n",
    "\n",
    "The URL contains the following parts:\n",
    "* the **base URL** **``https://api.nytimes.com/svc/search/v2/articlesearch.json``**\n",
    "* the base URL is followed by a question mark **``?``**, which introduces the **query**.\n",
    "* The query contains different **parameters**: **``q``**, **``begin``**, **``end``** and **``api-key``**\n",
    "* We want to search for the term \"Armenia\" in broadly the Second World War.\n",
    "* A list of all available parameters can be found [here]( https://developer.nytimes.com/article_search_v2.json#/Documentation/GET/articlesearch.json) and then click **Show details**.\n",
    "* all the parameters are joined using the **``&``** symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "key = open('/Users/kasparbeelen/Desktop/apikey.txt','r').read()\n",
    "#key = # put you API key here\n",
    "url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?q=armenia&begin_date=19140101&end_date=19180101&api-key='\n",
    "call = url+key\n",
    "data = requests.get(call).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Inspect the data using the JSON Viewer. Write `print(json.dumps(data))` and copy-paste the result [here](http://jsonviewer.stack.hu/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the articles are hidden under the 'response' key and then the 'docs' key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['response']['docs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: print the abstract of each article. Use the `get()` method, return \"NaN\" if the article lacks an abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for doc in data['response']['docs']:\n",
    "    print(doc.get('abstract','NaN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints only the first ten hits, while the total numbers of articles the mention Armenia is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['response']['meta']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the other results, we have to set the 'page' attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?'\n",
    "# instead of typing the url we use a dictionary the save the specifics of the query\n",
    "query_dict = {\n",
    "                'q':'armenia',\n",
    "                'begin_date':'19140101',\n",
    "                'end_date':'19180101',\n",
    "                'page':'3', # change the value here to download the other articles\n",
    "                'api-key':key}\n",
    "\n",
    "query = '&'.join(['='.join(item) for item in query_dict.items()])\n",
    "print(query[:-4])\n",
    "url = base_url + query\n",
    "print(url)\n",
    "data = requests.get(url).json()\n",
    "for doc in data['response']['docs']:\n",
    "    print(doc.get('abstract','NaN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Print the first 10 abstracts of the articles between 1938 and 1940 that mention the pattern 'jew'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?'\n",
    "# instead of typing the url we use a dictionary the save the specifics of the query\n",
    "query_dict = {\n",
    "                'q':'jew',\n",
    "                'begin_date':'19380101',\n",
    "                'end_date':'19400101',\n",
    "                'page':'1', # change the value here to download the other articles\n",
    "                'api-key':key}\n",
    "\n",
    "query = '&'.join(['='.join(item) for item in query_dict.items()])\n",
    "print(query[:-4])\n",
    "url = base_url + query\n",
    "print(url)\n",
    "data = requests.get(url).json()\n",
    "for doc in data['response']['docs']:\n",
    "    print(doc.get('abstract','NaN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you know how to use one API, learning the others will be a piece of cake. Try, for example, to obtain data from the [Guardian](http://open-platform.theguardian.com/) or ['Chronicling America'](https://chroniclingamerica.loc.gov/) is very similar. Let's have a look at Chronicling America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = 'New York'\n",
    "year = '1865'\n",
    "url=\"http://chroniclingamerica.loc.gov/search/pages/results/?state=\" +state + \"&date1=\" + year + \"&date2=\" + year + \"&dateFilterType=yearRange&sequence=1&sort=date&rows=100&format=json\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the value pairs after the ? to understand the parameters of the search. Explicitly, the first query URL will ask for newspapers:\n",
    "\n",
    "- from New Yokr (state=New York)\n",
    "- from the year 1865, (date1=1865&date2=1865&dateFilterType=yearRange)\n",
    "- only the front pages (sequence=1)\n",
    "- sorting by date (sort=date)\n",
    "- returning a maximum of five (rows=100)\n",
    "0 in JSON (format=json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newspaper_data = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(newspaper_data['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(newspaper_data['items'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(newspaper_data['items'][0]['ocr_eng'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Google Books API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pprint import pprint\n",
    "antwoord=urlopen(\"https://www.googleapis.com/books/v1/volumes?q=shakespeare\").read()\n",
    "data=json.loads(antwoord.decode(\"utf-8\"))\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Advanced Examples: Nested Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Example 1: Topical shifts over time\n",
    "\n",
    "The example in which we plotted the evolution of 'love' useful, but it is nonetheless quite slow, if we'd like to plot many other timelines. For each query the program iterates over all the 500.000+ songs. We can make this more efficient by using **nested dictionaries**. \n",
    "\n",
    "... What?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_nested_dict = {1960:{'a':5,'the':9},\n",
    "                1961:{'a':3,'the':10}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to access the word frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(a_nested_dict[1960])\n",
    "print(a_nested_dict[1960]['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the value of the at year 1961"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nested dictionary, a key maps to the value of type `dict`. In the example we map years to word frequencies for that year (we map years to a mapping between words and their frequencies). This make computing the historical change over time for different words much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The speed of your program: `Counter.update()` vs `dict.setdefault()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python there are many ways to obtain the same result. The most important factor is often **speed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install tqdm to monitor the progress of your script\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf = {} # an empty dictionary where we will save \n",
    "from tqdm import tqdm\n",
    "for row in tqdm(song_titles): # iterate over the song_titles variable\n",
    "\n",
    "    year,song_id,group,title = row.split('<SEP>') # parse the row using multiple assignment\n",
    "    year = int(year) # cast year as an integer\n",
    "    \n",
    "    \n",
    "    # here we add some lines to keep track of the total number of words by year\n",
    "    wf.setdefault(year,Counter())\n",
    "    \n",
    "    words = word_tokenize(title.lower()) # split the lowercased string into words\n",
    "    \n",
    "    # here start collecting yearly word frequencies\n",
    "    wf[year].update(Counter(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(wf[1960]['a'])\n",
    "print(wf[1961]['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf = {} # an empty dictionary where we will save \n",
    "from tqdm import tqdm\n",
    "for row in tqdm(song_titles): # iterate over the song_titles variable\n",
    "\n",
    "    year,song_id,group,title = row.split('<SEP>') # parse the row using multiple assignment\n",
    "    year = int(year) # cast year as an integer\n",
    "    \n",
    "    \n",
    "    # here we add some lines to keep track of the total number of words by year\n",
    "    wf.setdefault(year,{})\n",
    "    \n",
    "    words = word_tokenize(title.lower()) # split the lowercased string into words\n",
    "    \n",
    "    # here start collecting yearly word frequencies\n",
    "    for w in words:\n",
    "        wf[year].setdefault(w,0)\n",
    "        wf[year][w] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to loop through our corpus only once to get the frequency of a word at a certain point in time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(wf[1960]['a'])\n",
    "print(wf[1961]['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sure, sometimes a word might not appear. To avoid `KeyErrors` we use the `.get()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this does not work\n",
    "wf[1960]['madonna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this works, do you understand the syntax?\n",
    "wf[1960].get('madonna',0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below returns the same as the long program above but is much faster because we prepared everything as a nest dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = 'tears' # define query\n",
    "results = {} # empty dictionary to save frequencies by years\n",
    "for year in wf: # loop over all the keys in the wf dictionary which are the years\n",
    "    results[year] = wf[year].get(search,0.0) # get the value for word search in year year\n",
    "pandas.Series(results).plot() # plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sure we can also **normalize** the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = 'tears' # define query\n",
    "results = {} # empty dictionary to save frequencies by years\n",
    "for year in wf: # loop over all the keys in the wf dictionary which are the years\n",
    "    total = sum(wf[year].values()) # the sum of all the values equals the total word count for that year\n",
    "    results[year] = wf[year].get(search,0.0) / total # get the value for word search in year year and divide it by total \n",
    "pandas.Series(results).plot() # plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to understand line five\n",
    "a_nested_dict = {1960:{'a':5,'the':9},\n",
    "                1961:{'a':3,'the':10}}\n",
    "print(a_nested_dict[1960])\n",
    "print(a_nested_dict[1960].values())\n",
    "print(sum(a_nested_dict[1960].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: So far we only plotted the evolution of **one word over time**. A more realistic scenario would be to monitor topics. Instead of just one word, we'd like to see the presence of a set of semantically related words. Adapt the program below: it should iterate over a list of words and plot total word count over time.\n",
    "> Tip: use two for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = ['tears','cry','crying'] # define query\n",
    "results = {} # empty dictionary to save frequencies by years\n",
    "for year in wf: # loop over all the keys in the wf dictionary which are the years\n",
    "    total = #??\n",
    "    results.setdefault(#??)\n",
    "    for s in search:\n",
    "        #??\n",
    "    results[year] = results[year] / total # get the value for word search in year year and divide it by total \n",
    "pandas.Series #?? plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: In the previous exercises we only inspect evolutions over time. Can you make a nested dictionary which keeps track of word counts by band instead of by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf = {} # an empty dictionary where we will save \n",
    "from tqdm import tqdm\n",
    "for row in tqdm(song_titles): # iterate over the song_titles variable\n",
    "\n",
    "    year,song_id,group,title = row.split('<SEP>') # parse the row using multiple assignment\n",
    "    \n",
    "    # here start collecting yearly word frequencies\n",
    "    for w in words:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Rank the bands by their total word count.\n",
    "> Tip: the total word count is equal to the some of the values as in sum(wf[band name].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "\n",
    "for band in wf:\n",
    "    counter[band] = \n",
    "    # ??\n",
    "counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or use sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Map each group to the frequency with which they use the word 'love'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "\n",
    "for band in wf:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Examples 2: The Lexical Diversity of Pop Culture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute now (approximately) if topics of songs titles are becoming more or less diverse. \n",
    "\n",
    "This can be done by computing the type-token ratio or the \"lexical diversity\".\n",
    "\n",
    "From the [NLTK book](http://www.nltk.org/book/ch01.html):\n",
    "    \n",
    "> A token is the technical name for a sequence of characters â such as hairy, his, or :) â that we want to treat as a group. [...] A word type is the form or spelling of the word independently of its specific occurrences in a text â that is, the word considered as a unique item of vocabulary. \n",
    "\n",
    "The type-token ratio is then a measure of lexical diversity. It can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_title = 'love love love all I want is candy'\n",
    "tokens = song_title.split()\n",
    "print(tokens)\n",
    "types = set(tokens)\n",
    "print(types)\n",
    "ratio = len(types) / len(tokens)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum lexical diversity is one (each word in the corpus appears only once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_title = 'love all I want is candy'\n",
    "tokens = song_title.split()\n",
    "print(tokens)\n",
    "types = set(tokens)\n",
    "print(types)\n",
    "ratio = len(types) / len(tokens)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can compute the lexical diversity of song titles by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexdiv = {}\n",
    "for year in wf:\n",
    "    lexdiv[year] = len(wf[year]) / sum(wf[year].values())\n",
    "pandas.Series(lexdiv).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you are interested, try some of the above code to study band names!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - DIY Lists and dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by *Think Python* by Allen B. Downey (http://thinkpython.com), *Introduction to Programming Using Python* by Y. Liang (Pearson, 2013). Some exercises below have been taken from: http://www.ling.gu.se/~lager/python_exercises.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ex. 1: Consider the following strings `sentence1 = \"Mike and Lars kick the bucket\"` and `sentence2 = \"Bonny and Clyde are really famous\"`. Split these strings into words and create the following strings via list manipulation: `sentence3 = \"Mike and Lars are really famous\"` and `sentence4=\"Bonny+and+Clyde+kick+the+bucket\"` (mind the plus signs!). Can you print the middle letter of the fourth sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ex. 2: Create an empty list and add three names (strings) to it using the *append* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Please use a built-in function to determine the number of strings in the list below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "friend_list = ['John', 'Bob', 'John', 'Marry', 'Bob']\n",
    "#  your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Please remove both *John* names from the list below using a list method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "friend_list = ['John', 'Bob', 'John', 'Marry', 'Bob']\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Ex. 3: Consider the `lookup` dictionary below. The following letters are still missing from it: 'k':'kilo', 'l':'lima', 'm':'mike'. Add them to `lookup`! Could you spell the word \"marvellous\" in code language now? Collect these codes into the list object `msg`. Next, join the items in this list together with a comma and print the spelled out version!\n",
    "\n",
    "> lookup = {'a':'alfa', 'b':'bravo', 'c':'charlie', 'd':'delta', 'e':'echo', 'f':'foxtrot', 'g':'golf', 'h':'hotel', 'i':'india', 'j':'juliett', 'n':'november', 'o':'oscar', 'p':'papa', 'q':'quebec', 'r':'romeo', 's':'sierra', 't':'tango', 'u':'uniform', 'v':'victor', 'w':'whiskey', 'x':'x-ray', 'y':'yankee', 'z':'zulu'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Ex. 4: Collect the code terms in the lookup dict (`alpha`, `bravo`, ...) from the previous exercise into a list called `code_words`. Is this list alphabetically sorted? No? Then make sure that this list is sorted alphabetically. Now remove the items `victor`, `india` and `papa`. Append the words `pigeon` and `potato` at the end of this list. Combine this new list of items into a single string, using a semicolon as a delimiter and print this string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ex. 5: Write a program that given a long string containing multiple words, prints  the same string, except with the words in backwards order. For example, say I type the string:\n",
    "\n",
    "`My name is Kaspar von Beelen`\n",
    "Then I would see the string:\n",
    "\n",
    "`Beelen von Kaspar is name My`\n",
    "\n",
    "**Tip**: Try using a negative `step`.\n",
    "\n",
    "Extra: Try to do this in just one line of code!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
